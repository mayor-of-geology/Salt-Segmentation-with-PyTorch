{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecb6800",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac6dd45d",
    "outputId": "e7e04a76-3c5b-45e8-ff65-3a8348151d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/get_data.py\n",
    "\n",
    "from warnings import filterwarnings\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "def data(ROOT:Path) -> Tuple[DataFrame, DataFrame]:\n",
    "    \n",
    "    #getting data\n",
    "\n",
    "    train_df = read_csv(ROOT/'train.csv', index_col='id', usecols=[0])\n",
    "    depths_df = read_csv(ROOT/'depths.csv', index_col='id')\n",
    "    train_df = train_df.join(depths_df)\n",
    "    valid_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "    train_df['images'] = [ROOT/f'train/images/{idx}.png' for idx in train_df.index]\n",
    "    train_df['masks'] = [ROOT/f'train/masks/{idx}.png' for idx in train_df.index]\n",
    "\n",
    "    #splitting into train and test data\n",
    "    trainset, testset = train_test_split(train_df, test_size=0.2, random_state=32)\n",
    "    \n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f35259",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acf43dae",
    "outputId": "8b527576-621b-4b5d-b44f-36ab20758c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/dataloader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/dataloader.py\n",
    "\n",
    "from pathlib import Path\n",
    "from os import cpu_count\n",
    "from typing import Tuple\n",
    "from get_data import data\n",
    "from segdataset import SaltSegmentationDataset\n",
    "from augmentation import train_augs, test_augs\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "def create_loaders(DATA_PATH:Path, batch_size:int) -> Tuple[DataLoader, DataLoader]:\n",
    "    \n",
    "    traindata, testdata = data(DATA_PATH)\n",
    "    \n",
    "    #load dataset and apply augmentation techniques\n",
    "    trainset = SaltSegmentationDataset(traindata.images, traindata.masks, train_augs())\n",
    "    testset = SaltSegmentationDataset(testdata.images, testdata.masks, test_augs())\n",
    "\n",
    "    #WRAP AN iterable dataloader around the train images and masks\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, \n",
    "                             pin_memory=True if torch.cuda.is_available() else False , shuffle=True, num_workers=cpu_count())\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, \n",
    "                            pin_memory=True if torch.cuda.is_available() else False , num_workers=cpu_count())\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cd33df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0efc809c",
    "outputId": "8e02f39b-a589-48ef-a7a7-f7fc1b935d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/augmentation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/augmentation.py\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "def train_augs(prob:int=1) -> A.Compose:\n",
    "    return A.Compose([\n",
    "            A.Resize(128, 128),\n",
    "            A.PadIfNeeded(min_height=128, min_width=128, p=prob),\n",
    "            A.CropNonEmptyMaskIfExists(width=128, height=128, p=prob),\n",
    "            A.Superpixels(max_size=128),\n",
    "#             A.Normalize(),\n",
    "        ])\n",
    "\n",
    "def test_augs() -> A.Compose:\n",
    "    return A.Compose([\n",
    "            A.Resize(128, 128),\n",
    "#             A.Normalize()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b346a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be251b89",
    "outputId": "da660ddf-275c-448c-cd35-abe71a2df1cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/segdataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/segdataset.py\n",
    "\n",
    "from torchvision import io\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "class SaltSegmentationDataset(Dataset):\n",
    "    def __init__(self, imagePaths:Path, maskPaths:Path, augmentations) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        self.imagePaths = imagePaths\n",
    "        self.maskPaths = maskPaths\n",
    "        self.augmentations = augmentations\n",
    "#         self.train = train\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = io.read_image(str(self.imagePaths[idx]), mode=io.ImageReadMode.GRAY).permute(1, 2, 0).numpy()\n",
    "        mask = torch.tensor(cv2.cvtColor(cv2.imread(str(self.maskPaths[idx]), 1), cv2.COLOR_BGR2GRAY)).unsqueeze(2).numpy()\n",
    "        \n",
    "#         augment = DataFrame()\n",
    "        \n",
    "        augment = self.augmentations(image=image, mask=mask)            \n",
    "        image = augment['image']\n",
    "        mask = augment['mask']\n",
    "        \n",
    "        image = torch.Tensor(image).type(torch.float32)/255.0\n",
    "        mask = torch.Tensor(mask).type(torch.float32)/255.0\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7ac84a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1029273",
    "outputId": "0f9e2294-811a-4e4f-914d-5ca4281fcc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/architecture.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/architecture.py\n",
    "\n",
    "from torch import nn\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "class SaltSegmentationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SaltSegmentationModel, self).__init__()\n",
    "        \n",
    "        self.arc = smp.Unet(\n",
    "            encoder_name='timm-efficientnet-b0',\n",
    "            encoder_weights='imagenet',\n",
    "            in_channels=1,\n",
    "            classes=1,\n",
    "            activation=None\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, masks=None):\n",
    "        logits = self.arc(images)\n",
    "        \n",
    "        if masks != None:\n",
    "            dice_loss = DiceLoss(mode='binary')(logits, masks)\n",
    "            bce_loss = nn.BCEWithLogitsLoss()(logits, masks)\n",
    "            \n",
    "            return logits, dice_loss + bce_loss\n",
    "    \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf30d5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dc03b9e",
    "outputId": "5f834795-e24b-4a35-f633-429b85068753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/engine.py\n",
    "\n",
    "from typing import Tuple, List\n",
    "from numpy import Inf\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import device\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from script.architecture import SaltSegmentationModel\n",
    "\n",
    "import torch\n",
    "\n",
    "def train_func(dataloader:DataLoader, model:SaltSegmentationModel, optimizer:Adam) -> float:\n",
    "    \n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "\n",
    "        images = images.permute(0, 3, 1, 2); masks = masks.permute(0, 3, 1, 2)\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(images, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    return train_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def test_func(dataloader:DataLoader, model:SaltSegmentationModel) -> float:\n",
    "    \n",
    "    model.eval()\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    with torch.inference_mode():\n",
    "        for images, masks in tqdm(dataloader):\n",
    "            images = images.permute(0, 3, 1, 2); masks = masks.permute(0, 3, 1, 2)\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            \n",
    "            logits, loss = model(images, masks)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    return test_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def train(trainloader:DataLoader, testloader:DataLoader, model:SaltSegmentationModel,\n",
    "          optimizer:Adam, EPOCHS:int, DIR:Path) -> Tuple[List, List]:\n",
    "    \n",
    "    best_valid_loss = Inf\n",
    "\n",
    "    print(\"*\"*60)\n",
    "    print('                         START TRAINING               ')\n",
    "    print(\"*\"*60)\n",
    "    train_losses, test_losses = list(), list()\n",
    "    for i in tqdm(range(EPOCHS)):\n",
    "        train_loss = train_func(trainloader, model, optimizer)\n",
    "        test_loss = test_func(testloader, model)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if test_loss < best_valid_loss:\n",
    "            torch.save(model.state_dict(), DIR/'model/best_salt_model.pt')\n",
    "            print('SAVED MODEL')\n",
    "\n",
    "            best_valid_loss = test_loss\n",
    "\n",
    "        print(f'Epoch : {i+1} : Training loss : {train_loss} | Validation loss : {test_loss}')\n",
    "\n",
    "    print(\"*\"*60)\n",
    "    print('                         TRAINING ENDS               ')\n",
    "    print(\"*\"*60)\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2429581",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c65185c",
    "outputId": "8d184faa-4de7-4ed1-80ac-5202b6ecc49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train.py\n",
    "\n",
    "import os\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from script.dataloader import create_loaders\n",
    "from script.architecture import SaltSegmentationModel\n",
    "from script.engine import train\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "parser = ArgumentParser(description='Get some hyperparameters', add_help=True)\n",
    "\n",
    "parser.add_argument('-e', '--num_epochs', default=5, metavar='EPOCH', type=int, help='number of epochs')\n",
    "parser.add_argument('-bs', '--batch_size', default=32, type=int, help='number of batch or sample size')\n",
    "parser.add_argument('-lr', '--learning_rate', default=0.001, type=float, metavar='LR', help='learning rate')\n",
    "parser.add_argument('--data-dir', default=Path('./'), help='directory of training data', type=Path)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "#hyperparameters\n",
    "NUM_EPOCHS = args.num_epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "LR = args.learning_rate\n",
    "\n",
    "#data directory\n",
    "DIR = args.data_dir\n",
    "print(f'Data file path : {DIR}')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trainloader, testloader = create_loaders(DIR, BATCH_SIZE)\n",
    "\n",
    "model = SaltSegmentationModel().to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "def plot_loss():\n",
    "    train_losses, test_losses = train(trainloader, testloader, model, optimizer=optimizer, EPOCHS=NUM_EPOCHS, DIR=DIR)\n",
    "\n",
    "    # plot the training loss\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"train_loss\")\n",
    "    plt.plot(test_losses, label=\"test_loss\")\n",
    "    plt.title(\"Training Loss on Dataset\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.savefig(DIR/'pictures/losses.png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b0c9f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cf7915f",
    "outputId": "be02b523-83bc-49f5-9bbc-b7f21dee47d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/predict.py\n",
    "\n",
    "import torch\n",
    "from torchvision import io\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from script.architecture import SaltSegmentationModel\n",
    "from torchvision.transforms import Resize\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument('--image_path', type=str, help='Image to predict mask')\n",
    "\n",
    "parser.add_argument('--model_path', \n",
    "                    default=Path('./model/best_salt_model.pt'), type=str,\n",
    "                    help='Model Path')\n",
    "\n",
    "parser.add_argument('--image_name', type=str, help='Image to predict mask')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def load_model(filepath=args.model_path):\n",
    "  \n",
    "    model = SaltSegmentationModel().to(device)                             \n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_mask(image_path=args.image_path, filepath=args.model_path):\n",
    "\n",
    "    model = load_model(filepath)\n",
    "\n",
    "    image = io.read_image(str(image_path), mode=io.ImageReadMode.GRAY).numpy()#.permute(1, 2, 0).numpy()\n",
    "\n",
    "    image = torch.Tensor(image).type(torch.float32)/255.0\n",
    "\n",
    "    # Resize the image to be the same size as the model\n",
    "    transform = Resize(size=(128, 128))\n",
    "    image = transform(image)#.squeeze(dim=0) \n",
    "\n",
    "    # Predict on image\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        image = image.unsqueeze(1).to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        logits = model(image)\n",
    "        pred_mask = (torch.sigmoid(logits).type(torch.float32)) > 0.5 * 1.0\n",
    "\n",
    "    return image, pred_mask\n",
    "\n",
    "def plot_mask():\n",
    "\n",
    "    image, pred_mask = predict_mask(image_path=args.image_path, filepath=args.model_path)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "    ax1.set_title('IMAGE')\n",
    "    ax1.imshow(image.detach().cpu().squeeze(), cmap='seismic_r')\n",
    "\n",
    "    ax2.set_title('PREDICTED')\n",
    "    ax2.imshow(pred_mask.detach().cpu().squeeze(), cmap='jet')\n",
    "    \n",
    "    plt.savefig('./pictures/'+args.image_name+'.png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_mask()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c7b30ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e4d44d0",
    "outputId": "eb1402f2-55f2-4e0a-e279-f818e30d1dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file path : /content/drive/My Drive/Salt Dataset\n",
      "************************************************************\n",
      "                         START TRAINING               \n",
      "************************************************************\n",
      "  0% 0/5 [00:00<?, ?it/s]\n",
      "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 1/50 [00:08<06:46,  8.30s/it]\u001b[A\n",
      "  4% 2/50 [00:08<02:55,  3.66s/it]\u001b[A\n",
      "  6% 3/50 [00:09<01:41,  2.16s/it]\u001b[A\n",
      "  8% 4/50 [00:09<01:08,  1.48s/it]\u001b[A\n",
      " 10% 5/50 [00:09<00:49,  1.10s/it]\u001b[A\n",
      " 12% 6/50 [00:10<00:37,  1.16it/s]\u001b[A\n",
      " 14% 7/50 [00:11<00:34,  1.25it/s]\u001b[A\n",
      " 16% 8/50 [00:12<00:36,  1.15it/s]\u001b[A\n",
      " 18% 9/50 [00:12<00:33,  1.22it/s]\u001b[A\n",
      " 20% 10/50 [00:14<00:44,  1.11s/it]\u001b[A\n",
      " 22% 11/50 [00:15<00:38,  1.02it/s]\u001b[A\n",
      " 24% 12/50 [00:15<00:33,  1.14it/s]\u001b[A\n",
      " 26% 13/50 [00:16<00:33,  1.10it/s]\u001b[A\n",
      " 28% 14/50 [00:17<00:31,  1.13it/s]\u001b[A\n",
      " 30% 15/50 [00:18<00:30,  1.15it/s]\u001b[A\n",
      " 32% 16/50 [00:19<00:31,  1.10it/s]\u001b[A\n",
      " 34% 17/50 [00:20<00:30,  1.07it/s]\u001b[A\n",
      " 36% 18/50 [00:21<00:28,  1.11it/s]\u001b[A\n",
      " 38% 19/50 [00:22<00:29,  1.05it/s]\u001b[A\n",
      " 40% 20/50 [00:23<00:25,  1.16it/s]\u001b[A\n",
      " 42% 21/50 [00:24<00:27,  1.05it/s]\u001b[A\n",
      " 44% 22/50 [00:24<00:24,  1.14it/s]\u001b[A\n",
      " 46% 23/50 [00:25<00:23,  1.15it/s]\u001b[A\n",
      " 48% 24/50 [00:26<00:21,  1.20it/s]\u001b[A\n",
      " 50% 25/50 [00:27<00:23,  1.08it/s]\u001b[A\n",
      " 52% 26/50 [00:28<00:18,  1.27it/s]\u001b[A\n",
      " 54% 27/50 [00:29<00:21,  1.09it/s]\u001b[A\n",
      " 56% 28/50 [00:29<00:17,  1.24it/s]\u001b[A\n",
      " 58% 29/50 [00:30<00:18,  1.17it/s]\u001b[A\n",
      " 60% 30/50 [00:32<00:20,  1.04s/it]\u001b[A\n",
      " 62% 31/50 [00:33<00:22,  1.17s/it]\u001b[A\n",
      " 64% 32/50 [00:34<00:18,  1.05s/it]\u001b[A\n",
      " 66% 33/50 [00:35<00:16,  1.00it/s]\u001b[A\n",
      " 68% 34/50 [00:36<00:18,  1.13s/it]\u001b[A\n",
      " 70% 35/50 [00:37<00:14,  1.02it/s]\u001b[A\n",
      " 72% 36/50 [00:38<00:14,  1.02s/it]\u001b[A\n",
      " 74% 37/50 [00:39<00:10,  1.20it/s]\u001b[A\n",
      " 76% 38/50 [00:40<00:12,  1.00s/it]\u001b[A\n",
      " 78% 39/50 [00:40<00:09,  1.21it/s]\u001b[A\n",
      " 80% 40/50 [00:42<00:09,  1.00it/s]\u001b[A\n",
      " 82% 41/50 [00:42<00:07,  1.21it/s]\u001b[A\n",
      " 84% 42/50 [00:44<00:07,  1.01it/s]\u001b[A\n",
      " 86% 43/50 [00:44<00:05,  1.22it/s]\u001b[A\n",
      " 88% 44/50 [00:45<00:05,  1.03it/s]\u001b[A\n",
      " 90% 45/50 [00:46<00:03,  1.25it/s]\u001b[A\n",
      " 92% 46/50 [00:47<00:03,  1.01it/s]\u001b[A\n",
      " 94% 47/50 [00:47<00:02,  1.23it/s]\u001b[A\n",
      " 96% 48/50 [00:49<00:02,  1.01s/it]\u001b[A\n",
      " 98% 49/50 [00:49<00:00,  1.21it/s]\u001b[A\n",
      "100% 50/50 [00:50<00:00,  1.01s/it]\n",
      "\n",
      "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8% 1/13 [00:01<00:12,  1.04s/it]\u001b[A\n",
      " 23% 3/13 [00:01<00:05,  1.87it/s]\u001b[A\n",
      " 38% 5/13 [00:02<00:03,  2.66it/s]\u001b[A\n",
      " 54% 7/13 [00:02<00:01,  3.18it/s]\u001b[A\n",
      " 69% 9/13 [00:03<00:01,  3.50it/s]\u001b[A\n",
      " 85% 11/13 [00:03<00:00,  3.95it/s]\u001b[A\n",
      "100% 13/13 [00:03<00:00,  3.51it/s]\n",
      "SAVED MODEL\n",
      "Epoch : 1 : Training loss : 0.7536638075113297 | Validation loss : 0.5092294812202454\n",
      " 20% 1/5 [00:54<03:38, 54.58s/it]\n",
      "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 1/50 [00:03<03:14,  3.98s/it]\u001b[A\n",
      "  4% 2/50 [00:04<01:33,  1.95s/it]\u001b[A\n",
      "  6% 3/50 [00:06<01:25,  1.83s/it]\u001b[A\n",
      "  8% 4/50 [00:06<00:58,  1.27s/it]\u001b[A\n",
      " 10% 5/50 [00:07<00:58,  1.30s/it]\u001b[A\n",
      " 12% 6/50 [00:08<00:43,  1.01it/s]\u001b[A\n",
      " 14% 7/50 [00:09<00:48,  1.13s/it]\u001b[A\n",
      " 16% 8/50 [00:10<00:37,  1.11it/s]\u001b[A\n",
      " 18% 9/50 [00:11<00:42,  1.03s/it]\u001b[A\n",
      " 20% 10/50 [00:11<00:33,  1.19it/s]\u001b[A\n",
      " 22% 11/50 [00:13<00:37,  1.03it/s]\u001b[A\n",
      " 24% 12/50 [00:13<00:31,  1.21it/s]\u001b[A\n",
      " 26% 13/50 [00:16<00:52,  1.42s/it]\u001b[A\n",
      " 28% 14/50 [00:16<00:40,  1.12s/it]\u001b[A\n",
      " 30% 15/50 [00:18<00:40,  1.15s/it]\u001b[A\n",
      " 32% 16/50 [00:18<00:31,  1.08it/s]\u001b[A\n",
      " 34% 17/50 [00:20<00:36,  1.11s/it]\u001b[A\n",
      " 36% 18/50 [00:20<00:28,  1.11it/s]\u001b[A\n",
      " 38% 19/50 [00:21<00:32,  1.05s/it]\u001b[A\n",
      " 40% 20/50 [00:22<00:25,  1.16it/s]\u001b[A\n",
      " 42% 21/50 [00:23<00:28,  1.01it/s]\u001b[A\n",
      " 44% 22/50 [00:23<00:22,  1.22it/s]\u001b[A\n",
      " 46% 23/50 [00:25<00:24,  1.12it/s]\u001b[A\n",
      " 48% 24/50 [00:25<00:19,  1.33it/s]\u001b[A\n",
      " 50% 25/50 [00:26<00:22,  1.12it/s]\u001b[A\n",
      " 52% 26/50 [00:27<00:18,  1.32it/s]\u001b[A\n",
      " 54% 27/50 [00:28<00:22,  1.02it/s]\u001b[A\n",
      " 56% 28/50 [00:29<00:18,  1.17it/s]\u001b[A\n",
      " 58% 29/50 [00:30<00:18,  1.14it/s]\u001b[A\n",
      " 60% 30/50 [00:31<00:19,  1.05it/s]\u001b[A\n",
      " 62% 31/50 [00:31<00:15,  1.20it/s]\u001b[A\n",
      " 64% 32/50 [00:33<00:16,  1.07it/s]\u001b[A\n",
      " 66% 33/50 [00:33<00:14,  1.21it/s]\u001b[A\n",
      " 68% 34/50 [00:34<00:14,  1.10it/s]\u001b[A\n",
      " 70% 35/50 [00:35<00:11,  1.30it/s]\u001b[A\n",
      " 72% 36/50 [00:36<00:13,  1.03it/s]\u001b[A\n",
      " 74% 37/50 [00:36<00:10,  1.25it/s]\u001b[A\n",
      " 76% 38/50 [00:38<00:11,  1.06it/s]\u001b[A\n",
      " 78% 39/50 [00:38<00:08,  1.26it/s]\u001b[A\n",
      " 80% 40/50 [00:39<00:09,  1.11it/s]\u001b[A\n",
      " 82% 41/50 [00:40<00:06,  1.30it/s]\u001b[A\n",
      " 84% 42/50 [00:41<00:07,  1.11it/s]\u001b[A\n",
      " 86% 43/50 [00:42<00:05,  1.28it/s]\u001b[A\n",
      " 88% 44/50 [00:43<00:05,  1.14it/s]\u001b[A\n",
      " 90% 45/50 [00:43<00:03,  1.33it/s]\u001b[A\n",
      " 92% 46/50 [00:44<00:03,  1.23it/s]\u001b[A\n",
      " 94% 47/50 [00:45<00:02,  1.20it/s]\u001b[A\n",
      " 96% 48/50 [00:46<00:01,  1.18it/s]\u001b[A\n",
      " 98% 49/50 [00:47<00:00,  1.21it/s]\u001b[A\n",
      "100% 50/50 [00:47<00:00,  1.05it/s]\n",
      "\n",
      "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8% 1/13 [00:01<00:12,  1.07s/it]\u001b[A\n",
      " 23% 3/13 [00:01<00:05,  1.88it/s]\u001b[A\n",
      " 38% 5/13 [00:02<00:03,  2.60it/s]\u001b[A\n",
      " 54% 7/13 [00:02<00:01,  3.08it/s]\u001b[A\n",
      " 69% 9/13 [00:03<00:01,  3.83it/s]\u001b[A\n",
      " 77% 10/13 [00:03<00:00,  4.04it/s]\u001b[A\n",
      " 85% 11/13 [00:03<00:00,  3.92it/s]\u001b[A\n",
      "100% 13/13 [00:03<00:00,  3.41it/s]\n",
      "SAVED MODEL\n",
      "Epoch : 2 : Training loss : 0.4310513210296631 | Validation loss : 0.430341715996082\n",
      " 40% 2/5 [01:46<02:38, 52.95s/it]\n",
      "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 1/50 [00:03<02:30,  3.08s/it]\u001b[A\n",
      "  4% 2/50 [00:04<01:31,  1.91s/it]\u001b[A\n",
      "  6% 3/50 [00:05<01:27,  1.85s/it]\u001b[A\n",
      "  8% 4/50 [00:06<00:59,  1.29s/it]\u001b[A\n",
      " 10% 5/50 [00:07<00:59,  1.32s/it]\u001b[A\n",
      " 12% 6/50 [00:08<00:44,  1.01s/it]\u001b[A\n",
      " 14% 7/50 [00:09<00:45,  1.05s/it]\u001b[A\n",
      " 16% 8/50 [00:09<00:35,  1.17it/s]\u001b[A\n",
      " 18% 9/50 [00:11<00:43,  1.06s/it]\u001b[A\n",
      " 20% 10/50 [00:11<00:34,  1.15it/s]\u001b[A\n",
      " 22% 11/50 [00:13<00:41,  1.07s/it]\u001b[A\n",
      " 24% 12/50 [00:13<00:32,  1.15it/s]\u001b[A\n",
      " 26% 13/50 [00:14<00:36,  1.00it/s]\u001b[A\n",
      " 28% 14/50 [00:15<00:30,  1.20it/s]\u001b[A\n",
      " 30% 15/50 [00:16<00:36,  1.03s/it]\u001b[A\n",
      " 32% 16/50 [00:17<00:28,  1.18it/s]\u001b[A\n",
      " 34% 17/50 [00:18<00:32,  1.02it/s]\u001b[A\n",
      " 36% 18/50 [00:18<00:25,  1.24it/s]\u001b[A\n",
      " 38% 19/50 [00:20<00:31,  1.01s/it]\u001b[A\n",
      " 40% 20/50 [00:20<00:25,  1.20it/s]\u001b[A\n",
      " 42% 21/50 [00:22<00:29,  1.01s/it]\u001b[A\n",
      " 44% 22/50 [00:22<00:23,  1.20it/s]\u001b[A\n",
      " 46% 23/50 [00:23<00:24,  1.09it/s]\u001b[A\n",
      " 48% 24/50 [00:24<00:20,  1.30it/s]\u001b[A\n",
      " 50% 25/50 [00:25<00:24,  1.00it/s]\u001b[A\n",
      " 52% 26/50 [00:26<00:19,  1.22it/s]\u001b[A\n",
      " 54% 27/50 [00:27<00:20,  1.13it/s]\u001b[A\n",
      " 56% 28/50 [00:27<00:16,  1.34it/s]\u001b[A\n",
      " 58% 29/50 [00:29<00:20,  1.04it/s]\u001b[A\n",
      " 60% 30/50 [00:29<00:16,  1.25it/s]\u001b[A\n",
      " 62% 31/50 [00:31<00:19,  1.03s/it]\u001b[A\n",
      " 64% 32/50 [00:31<00:15,  1.17it/s]\u001b[A\n",
      " 66% 33/50 [00:32<00:16,  1.01it/s]\u001b[A\n",
      " 68% 34/50 [00:33<00:13,  1.22it/s]\u001b[A\n",
      " 70% 35/50 [00:34<00:14,  1.04it/s]\u001b[A\n",
      " 72% 36/50 [00:35<00:11,  1.25it/s]\u001b[A\n",
      " 74% 37/50 [00:36<00:12,  1.03it/s]\u001b[A\n",
      " 76% 38/50 [00:36<00:09,  1.24it/s]\u001b[A\n",
      " 78% 39/50 [00:38<00:10,  1.04it/s]\u001b[A\n",
      " 80% 40/50 [00:38<00:07,  1.26it/s]\u001b[A\n",
      " 82% 41/50 [00:39<00:08,  1.06it/s]\u001b[A\n",
      " 84% 42/50 [00:40<00:06,  1.28it/s]\u001b[A\n",
      " 86% 43/50 [00:41<00:06,  1.10it/s]\u001b[A\n",
      " 88% 44/50 [00:41<00:04,  1.32it/s]\u001b[A\n",
      " 90% 45/50 [00:43<00:04,  1.13it/s]\u001b[A\n",
      " 92% 46/50 [00:43<00:02,  1.35it/s]\u001b[A\n",
      " 94% 47/50 [00:44<00:02,  1.07it/s]\u001b[A\n",
      " 96% 48/50 [00:45<00:01,  1.29it/s]\u001b[A\n",
      " 98% 49/50 [00:45<00:00,  1.30it/s]\u001b[A\n",
      "100% 50/50 [00:46<00:00,  1.08it/s]\n",
      "\n",
      "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8% 1/13 [00:01<00:12,  1.04s/it]\u001b[A\n",
      " 23% 3/13 [00:01<00:04,  2.01it/s]\u001b[A\n",
      " 38% 5/13 [00:02<00:02,  2.78it/s]\u001b[A\n",
      " 54% 7/13 [00:02<00:01,  3.28it/s]\u001b[A\n",
      " 69% 9/13 [00:03<00:01,  3.63it/s]\u001b[A\n",
      " 85% 11/13 [00:03<00:00,  4.01it/s]\u001b[A\n",
      "100% 13/13 [00:03<00:00,  3.60it/s]\n",
      "SAVED MODEL\n",
      "Epoch : 3 : Training loss : 0.3719936221837997 | Validation loss : 0.3422038864630919\n",
      " 60% 3/5 [02:36<01:43, 51.76s/it]\n",
      "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 1/50 [00:03<02:52,  3.53s/it]\u001b[A\n",
      "  4% 2/50 [00:04<01:24,  1.76s/it]\u001b[A\n",
      "  6% 3/50 [00:06<01:37,  2.07s/it]\u001b[A\n",
      "  8% 4/50 [00:06<01:05,  1.42s/it]\u001b[A\n",
      " 10% 5/50 [00:08<00:59,  1.33s/it]\u001b[A\n",
      " 12% 6/50 [00:08<00:45,  1.02s/it]\u001b[A\n",
      " 14% 7/50 [00:09<00:47,  1.10s/it]\u001b[A\n",
      " 16% 8/50 [00:10<00:37,  1.13it/s]\u001b[A\n",
      " 18% 9/50 [00:11<00:43,  1.06s/it]\u001b[A\n",
      " 20% 10/50 [00:12<00:34,  1.16it/s]\u001b[A\n",
      " 22% 11/50 [00:13<00:36,  1.07it/s]\u001b[A\n",
      " 24% 12/50 [00:13<00:29,  1.29it/s]\u001b[A\n",
      " 26% 13/50 [00:15<00:36,  1.01it/s]\u001b[A\n",
      " 28% 14/50 [00:15<00:29,  1.22it/s]\u001b[A\n",
      " 30% 15/50 [00:17<00:36,  1.05s/it]\u001b[A\n",
      " 32% 16/50 [00:17<00:29,  1.16it/s]\u001b[A\n",
      " 34% 17/50 [00:18<00:33,  1.02s/it]\u001b[A\n",
      " 36% 18/50 [00:19<00:26,  1.19it/s]\u001b[A\n",
      " 38% 19/50 [00:20<00:30,  1.01it/s]\u001b[A\n",
      " 40% 20/50 [00:21<00:24,  1.22it/s]\u001b[A\n",
      " 42% 21/50 [00:22<00:28,  1.01it/s]\u001b[A\n",
      " 44% 22/50 [00:22<00:22,  1.22it/s]\u001b[A\n",
      " 46% 23/50 [00:24<00:26,  1.04it/s]\u001b[A\n",
      " 48% 24/50 [00:24<00:21,  1.23it/s]\u001b[A\n",
      " 50% 25/50 [00:25<00:23,  1.05it/s]\u001b[A\n",
      " 52% 26/50 [00:26<00:18,  1.26it/s]\u001b[A\n",
      " 54% 27/50 [00:27<00:22,  1.03it/s]\u001b[A\n",
      " 56% 28/50 [00:28<00:17,  1.25it/s]\u001b[A\n",
      " 58% 29/50 [00:29<00:20,  1.01it/s]\u001b[A\n",
      " 60% 30/50 [00:29<00:16,  1.23it/s]\u001b[A\n",
      " 62% 31/50 [00:31<00:19,  1.02s/it]\u001b[A\n",
      " 64% 32/50 [00:31<00:14,  1.20it/s]\u001b[A\n",
      " 66% 33/50 [00:33<00:16,  1.06it/s]\u001b[A\n",
      " 68% 34/50 [00:33<00:12,  1.27it/s]\u001b[A\n",
      " 70% 35/50 [00:34<00:13,  1.14it/s]\u001b[A\n",
      " 72% 36/50 [00:35<00:10,  1.34it/s]\u001b[A\n",
      " 74% 37/50 [00:36<00:11,  1.11it/s]\u001b[A\n",
      " 76% 38/50 [00:36<00:09,  1.33it/s]\u001b[A\n",
      " 78% 39/50 [00:38<00:10,  1.06it/s]\u001b[A\n",
      " 80% 40/50 [00:38<00:07,  1.27it/s]\u001b[A\n",
      " 82% 41/50 [00:39<00:07,  1.14it/s]\u001b[A\n",
      " 84% 42/50 [00:39<00:05,  1.36it/s]\u001b[A\n",
      " 86% 43/50 [00:41<00:06,  1.05it/s]\u001b[A\n",
      " 88% 44/50 [00:41<00:04,  1.27it/s]\u001b[A\n",
      " 90% 45/50 [00:43<00:04,  1.01it/s]\u001b[A\n",
      " 92% 46/50 [00:43<00:03,  1.23it/s]\u001b[A\n",
      " 94% 47/50 [00:45<00:02,  1.03it/s]\u001b[A\n",
      " 96% 48/50 [00:45<00:01,  1.24it/s]\u001b[A\n",
      " 98% 49/50 [00:46<00:00,  1.27it/s]\u001b[A\n",
      "100% 50/50 [00:46<00:00,  1.07it/s]\n",
      "\n",
      "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8% 1/13 [00:01<00:20,  1.68s/it]\u001b[A\n",
      " 23% 3/13 [00:02<00:08,  1.22it/s]\u001b[A\n",
      " 31% 4/13 [00:03<00:05,  1.54it/s]\u001b[A\n",
      " 38% 5/13 [00:03<00:04,  1.67it/s]\u001b[A\n",
      " 46% 6/13 [00:03<00:03,  1.96it/s]\u001b[A\n",
      " 54% 7/13 [00:04<00:02,  2.21it/s]\u001b[A\n",
      " 62% 8/13 [00:04<00:02,  2.19it/s]\u001b[A\n",
      " 69% 9/13 [00:04<00:01,  2.56it/s]\u001b[A\n",
      " 77% 10/13 [00:05<00:00,  3.07it/s]\u001b[A\n",
      " 85% 11/13 [00:05<00:00,  2.59it/s]\u001b[A\n",
      "100% 13/13 [00:05<00:00,  2.21it/s]\n",
      "SAVED MODEL\n",
      "Epoch : 4 : Training loss : 0.30109196782112124 | Validation loss : 0.31380408773055446\n",
      " 80% 4/5 [03:29<00:52, 52.26s/it]\n",
      "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 1/50 [00:04<03:24,  4.18s/it]\u001b[A\n",
      "  4% 2/50 [00:05<02:05,  2.62s/it]\u001b[A\n",
      "  6% 3/50 [00:08<02:13,  2.85s/it]\u001b[A\n",
      "  8% 4/50 [00:09<01:32,  2.01s/it]\u001b[A\n",
      " 10% 5/50 [00:11<01:33,  2.07s/it]\u001b[A\n",
      " 12% 6/50 [00:12<01:14,  1.69s/it]\u001b[A\n",
      " 14% 7/50 [00:14<01:19,  1.85s/it]\u001b[A\n",
      " 16% 8/50 [00:15<01:02,  1.49s/it]\u001b[A\n",
      " 18% 9/50 [00:17<01:04,  1.58s/it]\u001b[A\n",
      " 20% 10/50 [00:17<00:51,  1.28s/it]\u001b[A\n",
      " 22% 11/50 [00:19<00:48,  1.25s/it]\u001b[A\n",
      " 24% 12/50 [00:19<00:41,  1.09s/it]\u001b[A\n",
      " 26% 13/50 [00:20<00:34,  1.08it/s]\u001b[A\n",
      " 28% 14/50 [00:21<00:38,  1.06s/it]\u001b[A\n",
      " 30% 15/50 [00:22<00:30,  1.16it/s]\u001b[A\n",
      " 32% 16/50 [00:23<00:34,  1.01s/it]\u001b[A\n",
      " 34% 17/50 [00:23<00:27,  1.20it/s]\u001b[A\n",
      " 36% 18/50 [00:24<00:28,  1.13it/s]\u001b[A\n",
      " 38% 19/50 [00:25<00:23,  1.34it/s]\u001b[A\n",
      " 40% 20/50 [00:26<00:28,  1.06it/s]\u001b[A\n",
      " 42% 21/50 [00:27<00:22,  1.27it/s]\u001b[A\n",
      " 44% 22/50 [00:28<00:27,  1.03it/s]\u001b[A\n",
      " 46% 23/50 [00:29<00:21,  1.25it/s]\u001b[A\n",
      " 48% 24/50 [00:30<00:22,  1.14it/s]\u001b[A\n",
      " 50% 25/50 [00:30<00:18,  1.35it/s]\u001b[A\n",
      " 52% 26/50 [00:31<00:22,  1.08it/s]\u001b[A\n",
      " 54% 27/50 [00:32<00:18,  1.26it/s]\u001b[A\n",
      " 56% 28/50 [00:33<00:20,  1.10it/s]\u001b[A\n",
      " 58% 29/50 [00:33<00:16,  1.28it/s]\u001b[A\n",
      " 60% 30/50 [00:35<00:18,  1.10it/s]\u001b[A\n",
      " 62% 31/50 [00:35<00:14,  1.31it/s]\u001b[A\n",
      " 64% 32/50 [00:36<00:15,  1.13it/s]\u001b[A\n",
      " 66% 33/50 [00:37<00:14,  1.21it/s]\u001b[A\n",
      " 68% 34/50 [00:38<00:13,  1.17it/s]\u001b[A\n",
      " 70% 35/50 [00:39<00:12,  1.24it/s]\u001b[A\n",
      " 72% 36/50 [00:40<00:12,  1.08it/s]\u001b[A\n",
      " 74% 37/50 [00:40<00:10,  1.23it/s]\u001b[A\n",
      " 76% 38/50 [00:41<00:10,  1.12it/s]\u001b[A\n",
      " 78% 39/50 [00:42<00:09,  1.19it/s]\u001b[A\n",
      " 80% 40/50 [00:43<00:08,  1.16it/s]\u001b[A\n",
      " 82% 41/50 [00:44<00:08,  1.07it/s]\u001b[A\n",
      " 84% 42/50 [00:45<00:06,  1.23it/s]\u001b[A\n",
      " 86% 43/50 [00:46<00:06,  1.06it/s]\u001b[A\n",
      " 88% 44/50 [00:47<00:05,  1.18it/s]\u001b[A\n",
      " 90% 45/50 [00:48<00:04,  1.06it/s]\u001b[A\n",
      " 92% 46/50 [00:48<00:03,  1.20it/s]\u001b[A\n",
      " 94% 47/50 [00:49<00:02,  1.07it/s]\u001b[A\n",
      " 96% 48/50 [00:50<00:01,  1.20it/s]\u001b[A\n",
      " 98% 49/50 [00:51<00:00,  1.03it/s]\u001b[A\n",
      "100% 50/50 [00:52<00:00,  1.05s/it]\n",
      "\n",
      "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8% 1/13 [00:01<00:12,  1.04s/it]\u001b[A\n",
      " 23% 3/13 [00:01<00:05,  1.94it/s]\u001b[A\n",
      " 38% 5/13 [00:02<00:02,  2.78it/s]\u001b[A\n",
      " 54% 7/13 [00:02<00:01,  3.23it/s]\u001b[A\n",
      " 69% 9/13 [00:03<00:01,  3.62it/s]\u001b[A\n",
      " 85% 11/13 [00:03<00:00,  3.97it/s]\u001b[A\n",
      "100% 13/13 [00:03<00:00,  3.56it/s]\n",
      "Epoch : 5 : Training loss : 0.271039300262928 | Validation loss : 0.35841717972205234\n",
      "100% 5/5 [04:25<00:00, 53.17s/it]\n",
      "************************************************************\n",
      "                         TRAINING ENDS               \n"
     ]
    }
   ],
   "source": [
    "!python train.py --num_epochs 5 --batch_size 64 --learning_rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6a67d2f",
   "metadata": {
    "id": "2fe44c7a"
   },
   "outputs": [],
   "source": [
    "!python predict.py --image_path './images/739a2484b4.png' --image_name 'Mask5'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c84b0f6af3b91181ac42c1e4857f90b45abdad43bc5d11c0c8c194282206e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
